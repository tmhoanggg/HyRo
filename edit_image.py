import os
import argparse
import torch
import numpy as np
from PIL import Image
from diffusers import StableDiffusionInpaintPipeline
from detectron2.checkpoint import DetectionCheckpointer
from detectron2.config import get_cfg

# Assuming your Trainer or model architecture is accessible
from cat_seg import add_cat_seg_config
from train_net import Trainer 

class CATSegDiffusionEditor:
    def __init__(self, config_path, weights_path, device="cuda"):
        self.device = device
        # 1. Load your CAT-Seg / Hyperbolic Refined Model [cite: 60, 166]
        cfg = get_cfg()
        add_cat_seg_config(cfg)
        cfg.merge_from_file(config_path)
        cfg.MODEL.WEIGHTS = weights_path
        cfg.MODEL.DEVICE = device
        
        self.model = Trainer.build_model(cfg)
        self.model.eval()
        DetectionCheckpointer(self.model).resume_or_load(weights_path)
        
        # 2. Load Diffusion Pipeline (Stable Diffusion 2.0 Inpainting is a robust choice)
        self.diffusion_pipe = StableDiffusionInpaintPipeline.from_pretrained(
            "stable-diffusion-v1-5/stable-diffusion-inpainting",
            torch_dtype=torch.float16,
        ).to(device)

    @torch.no_grad()
    def get_mask(self, image_path, target_text):
        """
        Uses CAT-Seg's cost aggregation to find the target object.
        """
        img = Image.open(image_path).convert("RGB")
        width, height = img.size
        
        # Preprocessing as per Detectron2 / CAT-Seg requirements
        image_tensor = torch.as_tensor(np.array(img).transpose(2, 0, 1)).to(self.device)
        inputs = [{"image": image_tensor, "height": height, "width": width, "category_names": [target_text]}]
        
        # Forward pass through your cost-aggregation decoder [cite: 141, 351]
        outputs = self.model(inputs)
        
        # Extract binary mask from semantic segmentation output
        # Index 0 because we passed only one category [cite: 102]
        sem_seg = outputs[0]["sem_seg"]
        mask = (sem_seg.argmax(dim=0) == 0).cpu().numpy().astype(np.uint8) * 255
        return Image.fromarray(mask), img

    def edit(self, image_path, target_class, edit_prompt, negative_prompt=""):
        """
        Main editing function: Segments via CAT-Seg, then edits via Diffusion.
        """
        mask_img, original_img = self.get_mask(image_path, target_class)
        
        # The Diffusion process uses the mask generated by CAT-Seg's cost volume [cite: 54, 69]
        edited_image = self.diffusion_pipe(
            prompt=edit_prompt,
            negative_prompt=negative_prompt,
            image=original_img,
            mask_image=mask_img,
            # num_inference_steps=50,
            # guidance_scale=7.5
        ).images[0]
        
        return edited_image, mask_img

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", required=True)
    parser.add_argument("--config", required=True)
    parser.add_argument("--weights", required=True)
    parser.add_argument("--class_name", required=True, help="Text query for segmentation")
    parser.add_argument("--prompt", required=True, help="Edit prompt")
    parser.add_argument("--output", default="/kaggle/working/")
    args = parser.parse_args()


    editor = CATSegDiffusionEditor(
        config_path=args.config,
        weights_path=args.weights
    )
    
    result, debug_mask = editor.edit(
        image_path=args.input,
        target_class=args.class_name, 
        edit_prompt=args.prompt
    )
    
    result.save(os.path.join(args.output, "edited_image.png"))
    debug_mask.save(os.path.join(args.output, "mask.png"))